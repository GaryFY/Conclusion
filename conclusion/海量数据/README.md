海量数据处理
====

###实例    
####密匙一、分而治之/Hash映射 + Hash_map统计 + 堆/快速/归并排序    
		
1.  搜索引擎会通过日志文件把用户每次检索使用的所有检索串都记录下来，每个查询串的长度为1-255字节。
    假设目前有一千万个记录（这些查询串的重复度比较高，虽然总数是1千万，但如果除去重复后，不超过3百万个。
	一个查询串的重复度越高，说明查询它的用户越多，也就是越热门。），请你统计最热门的10个查询串，
	要求使用的内存不能超过1G。    

分析：
* 第一步：Query统计
如果利用排序，一千万条记录，每条记录是255Byte，很显然要占据2.375G内存，超过内存了。     
故采用**Hash Table法**:
维护一个Key为Query字串，Value为该Query出现次数的Hash Table，每次读取一个Query，如果不在table中，那么加入该字串，并
且将Value的值设为1；如果该字串已经在table中，那么将该字串的计数加一即可。**时间复杂度为O(n)**

* 第二步：找出Top10（**堆**）
算法：**维护一个一个大小为10(用K表示)的小根堆，然后遍历300万的Query，分别与根元素进行对比**，遍历时与堆顶元素进行对比，
如果该元素大小堆顶元素，那么把该元素放入堆中，然后更新整个堆，更新的复杂度为O(logK),如果小于堆顶元素，那么不更新。
时间复杂度为O(K)+O((N-K)*logK)=O(N*logK)

* 综上：最终时间复杂度：O（N） + N'*O（logK）。（N为1000万，N’为300万）
		
2. 题目：海量日志数据，提取出某日访问百度次数最多的那个IP。            
方案：IP的数目还是有限的，最多2^32个，所以可以考虑使用hash将ip直接存入内存，然后进行统计     
分析：分而治之/Hash映射+hash_map统计+堆/快速/归并排序
* 分而治之/Hash映射：针对数据大小，内存受限，把大文件化成小文件，即16字方针：大而化小，各个击破，缩小规模，逐个解决
具体实现：将ip取出来逐个写入一个大文件中，由于IP是32位，最多有2^32个IP，采用映射，%1000，把整个大文件映射为1000个文件

* hash_map统计：当大文件转化为小文件，采用常规的hash_map来进行频率统计     
具体实现：采用hash_map堆那1000个文件中的所有IP进行频率统计
* 堆/快速排序：统计完之后，便进行排序，得到次数最多的IP
		
3. 有一个1G大小的一个文件，里面每一行是一个词，词的大小不超过16字节，内存限制大小是1M。返回频数最高的100个词。       
* 分而治之/Hash映射：顺序读文件中，对于每个词x，取hash(x)%5000，然后按照该值存到5000个小文件中个，这样每个文件大概是200k
左右。如果其中的有的文件超过了1M大小，还可以按照类似的方法继续往下分，直到分解得到的小文件的大小都不超过1M。
* hash_map统计：对每个小文件，采用hash_map统计每个文件中出现的词以及相应的频率  
* 堆/归并排序：取出出现频率最大的100个词，再把100词及相应的频率存入文件，这样又得到了5000个文件，最后就是把这5000个文件
进行归并的过程了。
		
4. 海量数据分布在100台电脑中，想个办法高效统计出这批数据的Top10      
第一种情况：无重复           
* 堆排序：在每台电脑求出Top10，可以采用包含10个元素的堆完成（Top10小，用最大堆，Top10大，用最小堆）   
* 求出每台电脑上的Top10后，然后把这100台电脑的Top10组合起来，共1000个数据，再利用上面类似的方法求出Top10就可以了    
第二种情况：同一元素重复出现在不同的电脑中    
* 遍历一遍所有数据，重新hash取模，如此使得同一个元素只出现在单独的一台电脑中，然后采用上面的方法，统计每台电脑中
各个元素的出现次数找出Top10，继而组合100台电脑上的Top10，找出最终的Top10
		
5. 有10个文件，每个文件1G，每个文件的每一行存放的都是用户的query，每个文件的query都可能重复。   
要求你按照query的频度排序。   
* hash映射：顺序读取10个文件，按照hash(query)%10的结果将query写入到另外10个文件（a0,a1,...,a9）。这样新生成的文件每个
的大小大约也1G。
* hash_map统计：找一台内存在2G左右的机器，依次对用hash_map(query, query_count)来统计每个query出现的次数。
注：hash_map(query,query_count)是用来统计每个query的出现次数，不是存储他们的值，出现一次，则count+1。   
* 堆/快速/归并排序：利用快速/堆/归并排序按照出现次数进行排序，将排序好的query和对应的query_cout输出到文件中，
这样得到了10个排好序的文件（记为b0,b1,...,b9）。最后，对这10个文件进行归并排序（内排序与外排序相结合）。
		
6. 定a、b两个文件，各存放50亿个url，每个url各占64字节，内存限制是4G，让你找出a、b文件共同的url？     
* 分而治之/hash映射：遍历文件a，对每个url求取hash(url)%1000,然后根据所取得的值将url分别存储到1000个小文件
（记为a0,a1,...,a999）中.这样每个小文件的大约为300M。遍历文件b，采取和a相同的方式将url分别存储到1000小文件中
（记为b0,b1,...,b999）。这样处理后，**所有可能相同的url都在对应的小文件中，不对应的小文件不可能有相同的url**。
然后我们只要求出1000对小文件中相同的url即可。
* hash_set统计：求每对小文件中相同的url时，可以把其中一个小文件的url存储到hash_set中。然后遍历另一个小文件的每个url，
看其是否在刚才构建的hash_set中,如果是，那么就是共同的url，存到文件里面就可以了。
		
7. 怎么在海量数据中找出重复次数最多的一个？      
方案：先做hash，然后求模映射为小文件，求出每个小文件中重复次数最多的一个，并记录重复次数。
然后找出上一步求出的数据中重复次数最多的一个就是所求（具体参考前面的题）。
		
8. 上千万或上亿数据（有重复），统计其中出现次数最多的前N个数据。         
  方案：上千万或上亿的数据，现在的机器的内存应该能存下。所以考虑采用hash_map/搜索二叉树/红黑树等来进行统计次数。
  然后利用堆取出前N个出现次数最多的数据。
		
9. 一个文本文件，大约有一万行，每行一个词，要求统计出其中最频繁出现的前10个词，请给出思想，给出时间复杂度分析。       
* 方案1：如果文件比较大，无法一次性读入内存，可以采用hash取模的方法，将大文件分解为多个小文件，对于单个小文件利
用hash_map统计出每个小文件中10个最常出现的词，然后再进行归并处理，找出最终的10个最常出现的词。
* 方案2：通过hash取模将大文件分解为多个小文件后，除了可以用hash_map统计出每个小文件中10个最常出现的词，
也可以用trie树统计每个词出现的次数，时间复杂度是O(n*le)（le表示单词的平准长度），最终同样找出出现最频繁的前10个词
（可用堆来实现），时间复杂度是O(n*lg10)。
		
10. 1000万字符串，其中有些是重复的，需要把重复的全部去掉，保留没有重复的字符串。请怎么设计和实现？        
* 方案1：这题用trie树比较合适，hash_map也行。
* 方案2：1000w的数据规模插入操作完全不现实，以前试过在stl下100w元素插入set中已经慢得不能忍受，
觉得基于hash的实现不会比红黑树好太多，使用vector+sort+unique都要可行许多，建议还是先hash成小文件分开处理再综合。
		
**当数据量基本上int型key时，hash table是rbtree的3-4倍，但hash table一般会浪费大概一半内存。**

11. 一个文本文件，找出前10个经常出现的词，但这次文件比较长，说是上亿行或十亿行，总之无法一次读入内存，问最优解。         
方案1：首先根据用hash并求模，将文件分解为多个小文件，对于单个文件利用上题的方法求出每个文件件中10个最常出现的词。
然后再进行归并处理，找出最终的10个最常出现的词。
		
12. 100w个数中找出最大的100个数。
用一个含100个元素的最小堆完成。复杂度为O(100w*lg100)。   

####密匙二、多层划分
* 适用范围：第K大，中位数，不重复或重复的数字    
* 基本原理及要点：因为元素范围很大，不能利用直接寻址表，所以通过多次划分，逐步确定范围，
然后最后在一个可以接受的范围内进行。   
		
1. 2.5亿个整数中找出不重复的整数的个数，内存空间不足以容纳这2.5亿个整数。    
有点像鸽巢原理，整数个数为2^32,也就是，我们可以将这2^32个数，划分为2^8个区域(比如用单个文件代表一个区域)，
然后将数据分离到不同的区域，然后不同的区域在利用bitmap就可以直接解决了。也就是说只要有足够的磁盘空间，
就可以很方便的解决。
		
2. 5亿个int找它们的中位数。    
首先我们将int划分为2^16个区域，然后读取数据统计落到各个区域里的数的个数，之后我们根据统计结果就可以判断中位数
落到那个区域，同时知道这个区域中的第几大数刚好是中位数。然后第二次扫描我们只统计落在这个区域中的那些数就可以了。

		
####密匙三：Bloom filter/Bitmap
#####Bloom filter
* 适用范围：可以用来实现数据字典，进行数据的判重，或者集合求交集
* 原理：hash函数对应的值的位数组置1，查找时如果发现所有hash函数对应位都是1说明存在。    
hash函数个数k=(ln2)*(m/n)时错误率最小。在错误率不大于E的情况下，m至少要等于n*lg(1/E)才能表示任意n个元素的集合。
但m还应该更大些，因为还要保证bit数组里至少一半为0，则m应该>=nlg(1/E)*lge 大概就是nlg(1/E)1.44倍
(lg表示以2为底的对数)。举个例子我们假设错误率为0.01，则此时m应大概是n的13倍。这样k大概是8个。  
		
例：给你A,B两个文件，各存放50亿条URL，每条URL占用64字节，内存限制是4G，让你找出A,B文件共同的URL。
如果是三个乃至n个文件呢？     
		
计算下内存的占用，4G=2^32大概是40亿*8大概是340亿，n=50亿，如果按出错率0.01算需要的大概是650亿个bit。
现在可用的是340亿，相差并不多，这样可能会使出错率上升些。另外如果这些urlip是一一对应的，就可以转换成ip，则大大简单了。

		
#####Bitmap
例：在2.5亿个整数中找出不重复的整数，注，内存不足以容纳这2.5亿个整数。    
方案1：采用2-Bitmap（每个数分配2bit，00表示不存在，01表示出现一次，10表示多次，11无意义）进行，
共需内存2^32 * 2 bit=1 GB内存，还可以接受。然后扫描这2.5亿个整数，查看Bitmap中相对应位，
如果是00变01，01变10，10保持不变。所描完事后，查看bitmap，把对应位是01的整数输出即可。   
		
例：给40亿个不重复的unsigned int的整数，没排过序的，然后再给一个数，如何快速判断这个数是否在那40亿个数当中？
位图/Bitmap的方法，申请512M的内存，一个bit位代表一个unsigned int值。读入40亿个数，设置相应的bit位，
读入要查询的数，查看相应bit位是否为1，为1表示存在，为0表示不存在。

####密匙四：Trie树/数据库/倒排索引
#####Trie树

* 适用范围：数据量大，重复多，但是数据种类小可以放入内存
* 基本原理及要点：实现方式，节点孩子的表示方式
* 扩展：压缩实现。

#####倒排索引
倒排表以字或词为关键字进行索引，表中关键字所对应的记录表项记录了出现这个字或词的所有文档，一个表项就是一个字表段，
它记录该文档的ID和字符在该文档中出现的位置情况。**查询的时候由于可以一次得到查询关键字所对应的所有文档，
所以效率高于正排表**     

####密匙五、外排序
* 适用范围：大数据的排序，去重
* 基本原理及要点：外排序的归并方法，置换选择败者树原理，最优归并树